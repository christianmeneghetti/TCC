{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconhecimento de locutor por redes neurais (Machine Learning)\n",
    "\n",
    "Este projeto foi desenvolvido com o intuito de, através do aprendizado de maquina, reconhecer o locutor(detentor da feature de voz) utilizando o dataset previeamente usado no reconhecimento de digitos. \n",
    "\n",
    "Abaixo, é possível executar o código através das celulás de codigo do Jupyter Notebook, facilitando a visualização da aplicação como um todo.\n",
    "\n",
    "Informações de audio:   \n",
    "\n",
    "                        - Chroma stft\n",
    "                        - Rmse\n",
    "                        - Spectral Centroid\n",
    "                        - Spectral Bandwidth\n",
    "                        - Spectral RollOff\n",
    "                        - Zero Crossing Rate\n",
    "                        - Mfcc\n",
    "\n",
    "Este bloco de código está dividido em 3 seções:\n",
    "1. Extração de todas as informação dos arquivos de audio e salva-las em um arquivo CSV para leitura posterior.\n",
    "2. Treinamento do dataset recolhido de quatro participantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seção 1\n",
    "\n",
    "Nesta seção obteremos o resultado dos arquivos em csv para a utilização na modeladação da rede neural.\n",
    "\n",
    "```\n",
    "trainData     : ../data/recordings/train \n",
    "testData      : ../data/recordings/test\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quando verdadeiro, os arquivos de audio serão lidos e suas informações serão armazenadas em um arquivo CSV\n",
    "CREATE_CSV_FILES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os nomes dos arquivos de CSV\n",
    "TRAIN_CSV_FILE = \"train.csv\"\n",
    "TEST_CSV_FILE = \"test.csv\"\n",
    "# MORE_TRAIN_CSV_FILE = \"more_train.csv\"\n",
    "# MORE_TEST_CSV_FILE = \"more_test.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "FIUhv3GI8FOF",
    "outputId": "5adb2545-0d54-4494-c1bb-6fbb9f69ed45"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import librosa\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def extractWavFeatures(soundFilesFolder, csvFileName):\n",
    "    print(\"As informações dos arquivos de audio da pasta \"+soundFilesFolder+\" serão salvas no arquivo \"+csvFileName)\n",
    "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "    for i in range(1, 21):\n",
    "        header += f' mfcc{i}'\n",
    "    header += ' label'\n",
    "    header = header.split()\n",
    "    print('Cabeçalho do CSV: ', header)\n",
    "    file = open(csvFileName, 'w', newline='')\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    genres = '1 2 3 4 5 6 7 8 9 0'.split()\n",
    "    for filename in os.listdir(soundFilesFolder):\n",
    "        number = f'{soundFilesFolder}/{filename}'\n",
    "        y, sr = librosa.load(number, mono=True, duration=30)\n",
    "        # remove leading and trailing silence\n",
    "        y, index = librosa.effects.trim(y)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        writer.writerow(to_append.split())\n",
    "    file.close()\n",
    "    print(\"Fim da função de extração de dados\")\n",
    "\n",
    "if (CREATE_CSV_FILES == True):\n",
    "    extractWavFeatures(\"../data/recordings/train\", TRAIN_CSV_FILE)\n",
    "    extractWavFeatures(\"../data/recordings/test\", TEST_CSV_FILE)\n",
    "    # extractWavFeatures(\"../data/recordings/moreSpeakersTrain\", MORE_TRAIN_CSV_FILE)\n",
    "    # extractWavFeatures(\"../data/recordings/moreSpeakersTest\", MORE_TEST_CSV_FILE)\n",
    "    print(\"Os arquivos de CSV foram criados\")\n",
    "else:\n",
    "    print(\"A criação dos arquivos foram puladas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "_TZXrWYiNqCj",
    "outputId": "7d1d926e-64fa-4855-df66-207a97778915"
   },
   "outputs": [],
   "source": [
    "#Lendo o dataset e convertendo o as informaçoes em seus respectivos numeros\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def preProcessData(csvFileName):\n",
    "    print(csvFileName+ \" irá ser processado\")\n",
    "    data = pd.read_csv(csvFileName)\n",
    "    # Temos os quatro locutores abaixo: \n",
    "    # 0: Bianca\n",
    "    # 1: Christian \n",
    "    # 2: Paulo\n",
    "    # 3: Roseli\n",
    "    filenameArray = data['filename'] \n",
    "    \n",
    "    speakerArray = []\n",
    "    for i in range(len(filenameArray)):\n",
    "        speaker = filenameArray[i][2]\n",
    "        if speaker == \"b\":\n",
    "            speaker = \"0\"\n",
    "        elif speaker == \"c\":\n",
    "            speaker = \"1\"\n",
    "        elif speaker == \"p\":\n",
    "            speaker = \"2\"\n",
    "        elif speaker == \"r\":\n",
    "            speaker = \"3\"\n",
    "        speakerArray.append(speaker)\n",
    "    data['number'] = speakerArray\n",
    "    #Excluindo colunas desnecessárias\n",
    "    data = data.drop(['filename'],axis=1)\n",
    "    data = data.drop(['label'],axis=1)\n",
    "    data = data.drop(['chroma_stft'],axis=1)\n",
    "    data.shape\n",
    "\n",
    "    print(\"Pré processamento finalizado\")\n",
    "    return data\n",
    "\n",
    "trainData = preProcessData(TRAIN_CSV_FILE)\n",
    "testData = preProcessData(TEST_CSV_FILE)\n",
    "# moreTrainData = preProcessData(MORE_TRAIN_CSV_FILE)\n",
    "# moreTestData = preProcessData(MORE_TEST_CSV_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seção 2\n",
    "\n",
    "Nesta seção será feito o treinamento da rede neural utilizando o dataset de treianmento previamente pré procesasdo.\n",
    "\n",
    "Ao todo serão utilizadas as 50 repetições de cada número dos quatro participantes, em um total de 2000 arquivos de som.\n",
    "Para o teste e validação do treinamento será utilizado 1 repetição de cada número dos quatro participantes, em um total de 40 arquivos de som.\n",
    "\n",
    "Os arquivos utilizados para o treinamento e teste são provindos dos seguintes diretórios:\n",
    "* ../data/recordings/train\n",
    "* ../data/recordings/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UEy6oG8RQmnN"
   },
   "outputs": [],
   "source": [
    "# Quebrando o dataset para o treinamento, validação e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.array(trainData.iloc[:, :-1], dtype = float)\n",
    "y = trainData.iloc[:, -1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_test = np.array(testData.iloc[:, :-1], dtype = float)\n",
    "y_test = testData.iloc[:, -1]\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_val = encoder.fit_transform(y_val)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "print(\"Y do dataset(infomações) de treinamento:\", y_train.shape)\n",
    "print(\"Y do dataset(infomações) de validação:\", y_val.shape)\n",
    "print(\"Y do dataset(infomações) de teste:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S1o-OccqP5Ax",
    "outputId": "c93e0d6f-f5c0-4208-b0e5-7ecba885cddc"
   },
   "outputs": [],
   "source": [
    "# Normalizando o dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform( X_train )\n",
    "X_val = scaler.transform( X_val )\n",
    "X_test = scaler.transform( X_test )\n",
    "\n",
    "print(\"X do dataset(infomações) de treinamento:\", X_train.shape)\n",
    "print(\"X do dataset(infomações) de validação:\", X_val.shape)\n",
    "print(\"X do dataset(infomações) de teste:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "Q06tYXcdQZFp",
    "outputId": "8ab73b51-7592-450c-b152-8746e2f11b87"
   },
   "outputs": [],
   "source": [
    "# Criação do modelo de rede neural\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import keras\n",
    "\n",
    "# Modelo 1\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Processo de aprendizagem do modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Treinamento do modelo com 50 epocas e com um batch(lote) de 128\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=50,\n",
    "                    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "id": "z3nvtYKVa5HD",
    "outputId": "b858b37f-8e47-4cb4-a737-ef960246254b"
   },
   "outputs": [],
   "source": [
    "# Gráfico do histórico de treinamento\n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='Treinamento')\n",
    "pyplot.plot(history.history['val_loss'], label='Teste')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions to show the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpeaker(speaker):\n",
    "    speaker = str(speaker)\n",
    "    if speaker == \"0\":\n",
    "        return \"Bianca\"\n",
    "    elif speaker == \"1\":\n",
    "        return \"Christian\"\n",
    "    elif speaker == \"2\":\n",
    "        return \"Paulo\"\n",
    "    elif speaker == \"3\":\n",
    "        return \"Roseli\"\n",
    "    else: \n",
    "        speaker = \"Desconhecido\"\n",
    "        \n",
    "def printPrediction(X_data, y_data, printDigit):\n",
    "    print('\\n# Predições')\n",
    "    for i in range(len(y_data)):\n",
    "        prediction = getSpeaker(np.argmax(model.predict(X_data[i:i+1])[0], axis=-1))\n",
    "        speaker = getSpeaker(y_data[i])\n",
    "        if printDigit == True:\n",
    "            print(\"Numero={0:d}, y={1:10s}- predição={2:10s}- equivalencia={3}\".format(i, speaker, prediction, speaker==prediction))\n",
    "        else:\n",
    "            print(\"y={0:10s}- predição={1:10s}- equivalencia={2}\".format(speaker, prediction, speaker==prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def report(X_data, y_data):\n",
    "    # Matriz de confusão e Classificação\n",
    "    Y_pred = np.argmax(model.predict(X_data), axis=-1)\n",
    "    print(Y_pred)\n",
    "    y_test_num = y_data.astype(np.int64)\n",
    "    print(y_test_num)\n",
    "    conf_mt = confusion_matrix(y_test_num, Y_pred)\n",
    "    print(conf_mt)\n",
    "    plt.matshow(conf_mt)\n",
    "    plt.show()\n",
    "    print('\\nClassificação')\n",
    "    target_names = [\"Bianca\", \"Christian\", \"Paulo\", \"Roseli\"]\n",
    "    print(classification_report(y_test_num, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apresentando a performance do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "HSVxu84pRgZa",
    "outputId": "eb9242c9-7bff-4d54-a58c-60a915aad7d2"
   },
   "outputs": [],
   "source": [
    "print('\\n# DADOS TESTADOS #\\n')\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "# Predição\n",
    "printPrediction(X_test[:], y_test[:], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classifição dos dados testados\\n\")\n",
    "report(X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sound-regnize-Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa82987a71ca0339a52998cd22613b0c002bda8349fa32a0cb67ceec3936a2bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
